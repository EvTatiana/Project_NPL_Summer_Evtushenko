# Project_NPL_Summer_Evtushenko

ТЕМА

Определение идентичности современного вуза по медиатекстам методом тематического моедлирования

ЦЕЛЬ - провести анализ медиатекстов на русском языке методом извлечения ключевых слов и тематического моделирования и разработать алгоритм для определения идентичности российского ВУЗа на основе контент-анализа медиатектов.

ИССЛЕДОВАТЕЛЬСКИЙ ВОПРОС

Как идентичность проявляется в тех текстах, которые публикуются на сайтах вузов?

Какие ресурсы лучше использовать и какие значения параметров?

ПРАКТИЧЕСКАЯ И ТЕОРЕТИЧЕСКАЯ ЗНАЧИМОСТЬ 

Алгоритм исследования идентичности ВУЗов может быть использован для исследования идентичности разных учреждений, что важно для понимания того, как учреждение позиционирует себя в интернет-пространстве.

ЗАДАЧИ

1. Составить перечень ВУЗов, с сайтами которых будем работать (10 вузов разной направленности: политех, спортивный вуз, медицинский,классический...)
2. Отобрать из датасета, подготовленного с коллегами во время проекта Приоритет-2030, новости с вебсайтов 10 ВУЗов.
3. Сделать дополнительный парсинг, если не хватает новостей.
4. Предобработать данные. Сделать тематическое моделирование (LDA) в общем и для каждого ВУЗа в отдельности - 5-7 кластеров по 15 слов.
5. Выявить общие темы для современного ВУЗА. Выявить специфические темы для каждого из ВУЗов.
6. Найти оптимальные значения параметров (количесвто кластеров, ключевых слов)
7. Проанализировать частотные 2-граммы или 4-граммы для уточнения названия кластеров.
8. Сделать визуализацию в R для полученных данных

Перспективы работы 
9. Сделать синтаксическую разметку текстов. 
10. Найти триплеты - подлежащее, сказумое и дополнение? 
11. Сделать анализ контекстов справа и слева - конкордансы.

МАТЕРИАЛ ИССЛЕДОВАНИЯ - тексты, размещенные на сайтах российских ВУЗов на русском языке.

ПАЙПЛАЙН

Сбор материала с вебсайтов 10 вузов по 20-100 новостных текстов с каждого (готовый датасет в txt + Скрейпинг новых - requests)
Загрузка данных в датафрейм (pandas)
Создание общего корпуса (всех вузов) и подкорпусов (каждого в отдельности).
Токенизация и лемматизация текстов (pymorphy)
Выявление ключевых слов (tfidf)
Кластеризация подкорпусов (LDA)
Синтаксическая разметка (pymorphy или Natasha)
Анализ левого и правого контекста с названием или аббревиатурой ВУЗа (актор/действие)
ПЕРЕЧЕНЬ ВЕБСАЙТОВ ВУЗОВ Классические университеты ТГУ, СПбГУ, БФУ Технические многопрофильные университеты ТПУ, СПбПУ, БГТУ Медицинские и фармацевтические вузы САМГМУ Военные вузы и вузы силового блока ВАС Транспортные вузы ДВГУПС Спортивные ВУЗы СибСпорт, Ун. Лесгафта

Результаты

На данном этапе работы показано, что лучше всего анализ ключевых слов (по TfIdf) Модели LDA, Rake, Yake также можно использовать Для построения LDA лучше брать униграммы, иначе модель строить сложно, выдает неинтерпретируемые результаты Для анализа по ключевым словам (TfIdf) - униграммы и 4-граммы При установке следующих параметров - 7 кластеров, 15 ключевых слов LDA - 5 тем из 7 хорошо интерпретируются. При кластеризации всех ВУЗов только 2 из 7 тем интерпретируемы, однако одна из тем полностью покрывает темы, выделенные нами для разных университетов. Побочный результат - на R текст лучше очищается от стоп-слов, на выходе результаты лучше, чем получились на Python. Для контент-анализа медиатектов и выявления идентичности ВУЗов необходимо продолжить исследование с выделением именованных сущностей с последующим дистрибутивным анализом.

Для качественного анализа текстов с целью определения идентичности ВУЗа необходимо работать конкретно с каждым ВУЗом, так как определяющими факторами являются - территориальный компонент, федеральный/нефедеральный, классический/отраслевой. Все эти факторы формируют идентичность. Индивидуализированный подход, не коллективный.

Анализ контента из vk - отрицательный результат В отличие от Rake, Yake LDA дает более интерпретируемые результаты TfIdf для разных текстов одного ВУЗА- самый хороший результат 5 слов для анализа мало, 10 достаточно, но сложно выявить темы, 15-20 слов дает хороший результат Ngram = 1, 2 или Ngram = 4 или Ngram = 4, причем рассмотрение отдельно (LDA неинтерпретируема) Наиболее удачный вариант для LDA - 7 кластеров по 15 ключевых слов (n-gram = 1) Для TfIdf - n-gram = 1, 2 После удаления ключевых слов в R результат лучше интерпретируется

ПРОДОЛЖЕНИЕ ИССЛЕДОВАНИЯ - работа с конкордансом на корпусе с синтаксической разметкой для установления связей с именными сущностями (названия ВУЗов, университет, политех, кантиана…)
